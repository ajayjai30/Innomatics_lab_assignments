{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FEATURE EXTRACTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Embedding Method': ['Bag-of-Words', 'TF-IDF', 'Word2Vec'],\n",
    "    'Shape': [bow_features.shape, tfidf_features.shape, w2v_features.shape],\n",
    "    'Type': [type(bow_features).__name__, type(tfidf_features).__name__, type(w2v_features).__name__],\n",
    "    'Memory (MB)': [\n",
    "        bow_features.data.nbytes / 1024 / 1024 if hasattr(bow_features, 'data') else 0,\n",
    "        tfidf_features.data.nbytes / 1024 / 1024 if hasattr(tfidf_features, 'data') else 0,\n",
    "        w2v_features.nbytes / 1024 / 1024\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"- BoW: Simple, interpretable, sparse features\")\n",
    "print(\"- TF-IDF: Weighted frequency, reduces importance of common words\")\n",
    "print(\"- Word2Vec: Dense embeddings, captures semantic meaning, fixed dimension\")\n",
    "print(\"- BERT: Contextual embeddings, best semantic representation (GPU recommended)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a779e46",
   "metadata": {},
   "source": [
    "## Feature Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: BERT extraction is computationally expensive\n",
    "# Uncomment the code below to extract BERT embeddings (requires transformers and torch installed)\n",
    "\n",
    "# print(\"Extracting BERT embeddings...\")\n",
    "# bert_extractor = BERTExtractor(model_name='bert-base-uncased', device='cpu')\n",
    "# \n",
    "# # Extract embeddings in batches for efficiency\n",
    "# bert_features = bert_extractor.transform(df['cleaned_text'].values[:1000], batch_size=32)\n",
    "# \n",
    "# print(f\"BERT Features Shape: {bert_features.shape}\")\n",
    "# print(f\"Embedding dimension: {bert_features.shape[1]}\")\n",
    "# \n",
    "# joblib.dump(bert_extractor, r'C:\\Users\\admin\\Documents\\Innomatics\\Sentiment\\sentiment_analysis_project\\models\\bert_extractor.pkl')\n",
    "# print(\"BERT extractor saved!\")\n",
    "\n",
    "print(\"BERT extraction skipped in this notebook (requires GPU for efficient processing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9544a6",
   "metadata": {},
   "source": [
    "## Feature Extraction: BERT (Optional - Requires GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7dbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting Word2Vec embeddings...\")\n",
    "# Tokenize for Word2Vec\n",
    "tokenized_texts = [text.split() for text in df['cleaned_text'].values]\n",
    "\n",
    "w2v_extractor = Word2VecExtractor(vector_size=300, window=5, min_count=2)\n",
    "w2v_features = w2v_extractor.fit_transform(tokenized_texts)\n",
    "\n",
    "print(f\"Word2Vec Features Shape: {w2v_features.shape}\")\n",
    "print(f\"Embedding dimension: {w2v_features.shape[1]}\")\n",
    "\n",
    "# Save Word2Vec extractor\n",
    "joblib.dump(w2v_extractor, r'C:\\Users\\admin\\Documents\\Innomatics\\Sentiment\\sentiment_analysis_project\\models\\w2v_extractor.pkl')\n",
    "print(\"Word2Vec extractor saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac1f5d",
   "metadata": {},
   "source": [
    "## Feature Extraction: Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting TF-IDF features...\")\n",
    "tfidf_extractor = TFIDFExtractor(max_features=5000)\n",
    "tfidf_features = tfidf_extractor.fit_transform(df['cleaned_text'].values)\n",
    "\n",
    "print(f\"TF-IDF Features Shape: {tfidf_features.shape}\")\n",
    "print(f\"Vocabulary size: {len(tfidf_extractor.feature_names)}\")\n",
    "print(f\"Feature type: {type(tfidf_features)}\")\n",
    "\n",
    "# Save TF-IDF extractor\n",
    "joblib.dump(tfidf_extractor, r'C:\\Users\\admin\\Documents\\Innomatics\\Sentiment\\sentiment_analysis_project\\models\\tfidf_extractor.pkl')\n",
    "print(\"TF-IDF extractor saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a86bfd",
   "metadata": {},
   "source": [
    "## Feature Extraction: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting Bag-of-Words features...\")\n",
    "bow_extractor = BagOfWordsExtractor(max_features=5000)\n",
    "bow_features = bow_extractor.fit_transform(df['cleaned_text'].values)\n",
    "\n",
    "print(f\"BoW Features Shape: {bow_features.shape}\")\n",
    "print(f\"Vocabulary size: {len(bow_extractor.feature_names)}\")\n",
    "print(f\"Feature type: {type(bow_features)}\")\n",
    "\n",
    "# Save BoW extractor\n",
    "joblib.dump(bow_extractor, r'C:\\Users\\admin\\Documents\\Innomatics\\Sentiment\\sentiment_analysis_project\\models\\bow_extractor.pkl')\n",
    "print(\"BoW extractor saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c65afe",
   "metadata": {},
   "source": [
    "## Feature Extraction: Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\admin\\Documents\\Innomatics\\Sentiment\\sentiment_analysis_project\\data\\preprocessed_reviews.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset loaded: {len(df)} reviews\")\n",
    "print(f\"Positive: {(df['Sentiment']==1).sum()}, Negative: {(df['Sentiment']==0).sum()}\")\n",
    "print(f\"Cleaned text sample: {df['cleaned_text'].iloc[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5025290",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\admin\\Documents\\Innomatics\\Sentiment\\sentiment_analysis_project\\src')\n",
    "\n",
    "from feature_extraction import BagOfWordsExtractor, TFIDFExtractor, Word2VecExtractor, BERTExtractor\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2b233",
   "metadata": {},
   "source": [
    "# 3. Feature Extraction (Text Embedding)\n",
    "## Extracting Numerical Features from Reviews\n",
    "\n",
    "In this notebook, we will:\n",
    "- Load preprocessed reviews\n",
    "- Extract Bag-of-Words (BoW) features\n",
    "- Extract TF-IDF features\n",
    "- Extract Word2Vec embeddings\n",
    "- Extract BERT embeddings\n",
    "- Compare and analyze different embedding techniques"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
